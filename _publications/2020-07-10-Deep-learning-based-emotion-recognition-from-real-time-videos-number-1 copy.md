---
title: "Deep learning-based emotion recognition from real-time videos"
collection: publications
permalink: /publication/2020-07-10-Deep-learning-based-emotion-recognition-from-real-time-videos
# excerpt: 'This paper is about the number 1. The number 2 is left for future work.'
date: 2020-07-10
venue: 'International Conference on Human-Computer Interaction'
paperurl: 'https://hku.welight.fun/wenbin/files/2020-07-10-Deep-learning-based-emotion-recognition-from-real-time-videos.pdf'
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---

**Abstract:** We introduce a novel framework for emotional state detection from facial expression targeted to learning environments. Our framework is based on a convolutional deep neural network that classifies people’s emotions that are captured through a web-cam. For our classification outcome we adopt Russel’s model of core affect in which any particular emotion can be placed in one of four quadrants: pleasant-active, pleasant-inactive, unpleasant-active, and unpleasant-inactive. We gathered data from various datasets that were normalized and used to train the deep learning model. We use the fully-connected layers of the VGG S network which was trained on human facial expressions that were manually labeled. We have tested our application by splitting the data into 80:20 and re-training the model. The overall test accuracy of all detected emotions was 66%. We have a working application that is capable of reporting the user emotional state at about five frames per second on a standard laptop computer with a web-cam. The emotional state detector will be integrated into an affective pedagogical agent system where it will serve as a feedback to an intelligent animated educational tutor.
